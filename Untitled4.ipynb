{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAQdIXiB0tK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ae91f51-1635-44d9-f717-097896d4c89d"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t\n",
        "\tmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY))\n",
        "\t\n",
        "\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "WARNING:tensorflow:From <ipython-input-1-27cf9b1b6ace>:73: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 1.6998 - accuracy: 0.3720 - val_loss: 1.2995 - val_accuracy: 0.5260\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.2671 - accuracy: 0.5442 - val_loss: 1.0426 - val_accuracy: 0.6263\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 1.0817 - accuracy: 0.6184 - val_loss: 0.9302 - val_accuracy: 0.6725\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.9666 - accuracy: 0.6611 - val_loss: 0.8808 - val_accuracy: 0.6886\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.8916 - accuracy: 0.6869 - val_loss: 0.7743 - val_accuracy: 0.7259\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.8333 - accuracy: 0.7099 - val_loss: 0.8163 - val_accuracy: 0.7247\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7992 - accuracy: 0.7221 - val_loss: 0.6739 - val_accuracy: 0.7681\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7664 - accuracy: 0.7361 - val_loss: 0.6848 - val_accuracy: 0.7682\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7407 - accuracy: 0.7469 - val_loss: 0.6721 - val_accuracy: 0.7749\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7157 - accuracy: 0.7550 - val_loss: 0.7184 - val_accuracy: 0.7605\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.7005 - accuracy: 0.7610 - val_loss: 0.6281 - val_accuracy: 0.7897\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6786 - accuracy: 0.7686 - val_loss: 0.6305 - val_accuracy: 0.7893\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6634 - accuracy: 0.7710 - val_loss: 0.6337 - val_accuracy: 0.7910\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6539 - accuracy: 0.7767 - val_loss: 0.6524 - val_accuracy: 0.7860\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6356 - accuracy: 0.7818 - val_loss: 0.5869 - val_accuracy: 0.8003\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6248 - accuracy: 0.7858 - val_loss: 0.6096 - val_accuracy: 0.8002\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6133 - accuracy: 0.7879 - val_loss: 0.6083 - val_accuracy: 0.8010\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6041 - accuracy: 0.7914 - val_loss: 0.6145 - val_accuracy: 0.8056\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5945 - accuracy: 0.7956 - val_loss: 0.5834 - val_accuracy: 0.8109\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5851 - accuracy: 0.7989 - val_loss: 0.5772 - val_accuracy: 0.8061\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5813 - accuracy: 0.7996 - val_loss: 0.6159 - val_accuracy: 0.8001\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5770 - accuracy: 0.8026 - val_loss: 0.5778 - val_accuracy: 0.8098\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5699 - accuracy: 0.8040 - val_loss: 0.5948 - val_accuracy: 0.8044\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5599 - accuracy: 0.8070 - val_loss: 0.5962 - val_accuracy: 0.8085\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5524 - accuracy: 0.8116 - val_loss: 0.5750 - val_accuracy: 0.8171\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5557 - accuracy: 0.8094 - val_loss: 0.5486 - val_accuracy: 0.8195\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5415 - accuracy: 0.8126 - val_loss: 0.6287 - val_accuracy: 0.8047\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5381 - accuracy: 0.8143 - val_loss: 0.5306 - val_accuracy: 0.8252\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5411 - accuracy: 0.8149 - val_loss: 0.6644 - val_accuracy: 0.7906\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5253 - accuracy: 0.8189 - val_loss: 0.6011 - val_accuracy: 0.8111\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5332 - accuracy: 0.8160 - val_loss: 0.6597 - val_accuracy: 0.7964\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5259 - accuracy: 0.8178 - val_loss: 0.5272 - val_accuracy: 0.8269\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5276 - accuracy: 0.8199 - val_loss: 0.5904 - val_accuracy: 0.8085\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5175 - accuracy: 0.8206 - val_loss: 0.5328 - val_accuracy: 0.8310\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5139 - accuracy: 0.8251 - val_loss: 0.5314 - val_accuracy: 0.8281\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5138 - accuracy: 0.8235 - val_loss: 0.5032 - val_accuracy: 0.8358\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.5134 - accuracy: 0.8239 - val_loss: 0.5223 - val_accuracy: 0.8295\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5023 - accuracy: 0.8274 - val_loss: 0.5147 - val_accuracy: 0.8367\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5097 - accuracy: 0.8245 - val_loss: 0.6436 - val_accuracy: 0.7972\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.4997 - accuracy: 0.8286 - val_loss: 0.5593 - val_accuracy: 0.8237\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5042 - accuracy: 0.8261 - val_loss: 0.5276 - val_accuracy: 0.8298\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4996 - accuracy: 0.8266 - val_loss: 0.5747 - val_accuracy: 0.8214\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.5015 - accuracy: 0.8274 - val_loss: 0.5754 - val_accuracy: 0.8225\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4963 - accuracy: 0.8311 - val_loss: 0.5438 - val_accuracy: 0.8271\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4918 - accuracy: 0.8318 - val_loss: 0.5802 - val_accuracy: 0.8198\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4934 - accuracy: 0.8291 - val_loss: 0.5375 - val_accuracy: 0.8301\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4890 - accuracy: 0.8338 - val_loss: 0.4815 - val_accuracy: 0.8449\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4860 - accuracy: 0.8330 - val_loss: 0.5411 - val_accuracy: 0.8302\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4792 - accuracy: 0.8341 - val_loss: 0.5495 - val_accuracy: 0.8220\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4837 - accuracy: 0.8339 - val_loss: 0.5429 - val_accuracy: 0.8323\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4832 - accuracy: 0.8336 - val_loss: 0.5454 - val_accuracy: 0.8273\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4838 - accuracy: 0.8333 - val_loss: 0.5773 - val_accuracy: 0.8230\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4784 - accuracy: 0.8362 - val_loss: 0.5391 - val_accuracy: 0.8280\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4794 - accuracy: 0.8341 - val_loss: 0.5546 - val_accuracy: 0.8298\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.4782 - accuracy: 0.8370 - val_loss: 0.4976 - val_accuracy: 0.8397\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4750 - accuracy: 0.8379 - val_loss: 0.5377 - val_accuracy: 0.8307\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4734 - accuracy: 0.8365 - val_loss: 0.5670 - val_accuracy: 0.8288\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4703 - accuracy: 0.8397 - val_loss: 0.5172 - val_accuracy: 0.8353\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.4761 - accuracy: 0.8390 - val_loss: 0.5319 - val_accuracy: 0.8342\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4718 - accuracy: 0.8383 - val_loss: 0.5069 - val_accuracy: 0.8458\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4732 - accuracy: 0.8391 - val_loss: 0.5464 - val_accuracy: 0.8303\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4654 - accuracy: 0.8397 - val_loss: 0.4715 - val_accuracy: 0.8531\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4699 - accuracy: 0.8393 - val_loss: 0.5042 - val_accuracy: 0.8462\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4687 - accuracy: 0.8405 - val_loss: 0.5901 - val_accuracy: 0.8149\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4650 - accuracy: 0.8406 - val_loss: 0.5395 - val_accuracy: 0.8328\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4643 - accuracy: 0.8407 - val_loss: 0.5671 - val_accuracy: 0.8290\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4600 - accuracy: 0.8417 - val_loss: 0.5009 - val_accuracy: 0.8473\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.4629 - accuracy: 0.8416 - val_loss: 0.5055 - val_accuracy: 0.8472\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 24s 31ms/step - loss: 0.4597 - accuracy: 0.8427 - val_loss: 0.5100 - val_accuracy: 0.8402\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4590 - accuracy: 0.8445 - val_loss: 0.5119 - val_accuracy: 0.8369\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4594 - accuracy: 0.8427 - val_loss: 0.5205 - val_accuracy: 0.8405\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4607 - accuracy: 0.8423 - val_loss: 0.5341 - val_accuracy: 0.8350\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4595 - accuracy: 0.8426 - val_loss: 0.5190 - val_accuracy: 0.8414\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4522 - accuracy: 0.8442 - val_loss: 0.5820 - val_accuracy: 0.8281\n",
            "Epoch 75/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4600 - accuracy: 0.8430 - val_loss: 0.5308 - val_accuracy: 0.8359\n",
            "Epoch 76/100\n",
            "781/781 [==============================] - 25s 31ms/step - loss: 0.4522 - accuracy: 0.8455 - val_loss: 0.5583 - val_accuracy: 0.8329\n",
            "Epoch 77/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4559 - accuracy: 0.8447 - val_loss: 0.5194 - val_accuracy: 0.8443\n",
            "Epoch 78/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4507 - accuracy: 0.8472 - val_loss: 0.5219 - val_accuracy: 0.8381\n",
            "Epoch 79/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4597 - accuracy: 0.8433 - val_loss: 0.5085 - val_accuracy: 0.8426\n",
            "Epoch 80/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4559 - accuracy: 0.8431 - val_loss: 0.5065 - val_accuracy: 0.8439\n",
            "Epoch 81/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4514 - accuracy: 0.8444 - val_loss: 0.5831 - val_accuracy: 0.8237\n",
            "Epoch 82/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4475 - accuracy: 0.8473 - val_loss: 0.5398 - val_accuracy: 0.8294\n",
            "Epoch 83/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4489 - accuracy: 0.8481 - val_loss: 0.5118 - val_accuracy: 0.8438\n",
            "Epoch 84/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4501 - accuracy: 0.8463 - val_loss: 0.4873 - val_accuracy: 0.8476\n",
            "Epoch 85/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4542 - accuracy: 0.8456 - val_loss: 0.5541 - val_accuracy: 0.8286\n",
            "Epoch 86/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4512 - accuracy: 0.8464 - val_loss: 0.5241 - val_accuracy: 0.8371\n",
            "Epoch 87/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4542 - accuracy: 0.8455 - val_loss: 0.5391 - val_accuracy: 0.8359\n",
            "Epoch 88/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4509 - accuracy: 0.8459 - val_loss: 0.5089 - val_accuracy: 0.8484\n",
            "Epoch 89/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4546 - accuracy: 0.8442 - val_loss: 0.5227 - val_accuracy: 0.8395\n",
            "Epoch 90/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4385 - accuracy: 0.8521 - val_loss: 0.5224 - val_accuracy: 0.8387\n",
            "Epoch 91/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4511 - accuracy: 0.8458 - val_loss: 0.5665 - val_accuracy: 0.8253\n",
            "Epoch 92/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4463 - accuracy: 0.8492 - val_loss: 0.5838 - val_accuracy: 0.8247\n",
            "Epoch 93/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4418 - accuracy: 0.8496 - val_loss: 0.5166 - val_accuracy: 0.8369\n",
            "Epoch 94/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4466 - accuracy: 0.8476 - val_loss: 0.5551 - val_accuracy: 0.8333\n",
            "Epoch 95/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4521 - accuracy: 0.8471 - val_loss: 0.5307 - val_accuracy: 0.8372\n",
            "Epoch 96/100\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4416 - accuracy: 0.8501 - val_loss: 0.5271 - val_accuracy: 0.8377\n",
            "Epoch 97/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4543 - accuracy: 0.8458 - val_loss: 0.4885 - val_accuracy: 0.8436\n",
            "Epoch 98/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4499 - accuracy: 0.8466 - val_loss: 0.5220 - val_accuracy: 0.8380\n",
            "Epoch 99/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4503 - accuracy: 0.8470 - val_loss: 0.5243 - val_accuracy: 0.8377\n",
            "Epoch 100/100\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.4435 - accuracy: 0.8491 - val_loss: 0.5382 - val_accuracy: 0.8364\n",
            "> 83.640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MLKGBG3Gnkp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "20836c09-725c-4866-9b63-4ec2ecc35270"
      },
      "source": [
        "# evaluate model\n",
        "acc = history.evaluate(testX, testY, verbose=1)\n",
        "print(\"Test Accuracy :\", acc[1]*100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-77cec154a860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7wMjiqy4QkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "e866a1b1-b28f-432f-ec0e-34a412f20b5f"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "# learning curves\n",
        "summarize_diagnostics(history)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ff74771895c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}