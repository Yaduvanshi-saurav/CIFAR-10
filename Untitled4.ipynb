{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIAQdIXiB0tK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a59414d1-dba3-4514-e856-3c7f76091e90"
      },
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        " \n",
        "# load train and test dataset\n",
        "def load_dataset():\n",
        "\t# load dataset\n",
        "\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t# one hot encode target values\n",
        "\ttrainY = to_categorical(trainY)\n",
        "\ttestY = to_categorical(testY)\n",
        "\treturn trainX, trainY, testX, testY\n",
        " \n",
        "# scale pixels\n",
        "def prep_pixels(train, test):\n",
        "\t# convert from integers to floats\n",
        "\ttrain_norm = train.astype('float32')\n",
        "\ttest_norm = test.astype('float32')\n",
        "\t# normalize to range 0-1\n",
        "\ttrain_norm = train_norm / 255.0\n",
        "\ttest_norm = test_norm / 255.0\n",
        "\t# return normalized images\n",
        "\treturn train_norm, test_norm\n",
        " \n",
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\t\n",
        "\tmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "\t# load dataset\n",
        "\ttrainX, trainY, testX, testY = load_dataset()\n",
        "\t# prepare pixel data\n",
        "\ttrainX, testX = prep_pixels(trainX, testX)\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
        "\t# prepare iterator\n",
        "\tit_train = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\t# fit model\n",
        "\tsteps = int(trainX.shape[0] / 64)\n",
        "\thistory = model.fit_generator(it_train, steps_per_epoch=steps, epochs=100, validation_data=(testX, testY))\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(testX, testY, verbose=0)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "WARNING:tensorflow:From <ipython-input-1-91b648858830>:89: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 1.7488 - accuracy: 0.3492 - val_loss: 1.3290 - val_accuracy: 0.5131\n",
            "Epoch 2/100\n",
            "781/781 [==============================] - 334s 428ms/step - loss: 1.3378 - accuracy: 0.5131 - val_loss: 1.0958 - val_accuracy: 0.6105\n",
            "Epoch 3/100\n",
            "781/781 [==============================] - 334s 428ms/step - loss: 1.1441 - accuracy: 0.5916 - val_loss: 0.9738 - val_accuracy: 0.6638\n",
            "Epoch 4/100\n",
            "781/781 [==============================] - 334s 428ms/step - loss: 1.0154 - accuracy: 0.6420 - val_loss: 0.8531 - val_accuracy: 0.7057\n",
            "Epoch 5/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.9345 - accuracy: 0.6725 - val_loss: 0.8064 - val_accuracy: 0.7233\n",
            "Epoch 6/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.8755 - accuracy: 0.6949 - val_loss: 0.7402 - val_accuracy: 0.7440\n",
            "Epoch 7/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.8284 - accuracy: 0.7116 - val_loss: 0.7328 - val_accuracy: 0.7505\n",
            "Epoch 8/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.7932 - accuracy: 0.7266 - val_loss: 0.7501 - val_accuracy: 0.7453\n",
            "Epoch 9/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.7563 - accuracy: 0.7396 - val_loss: 0.6883 - val_accuracy: 0.7663\n",
            "Epoch 10/100\n",
            "781/781 [==============================] - 335s 428ms/step - loss: 0.7369 - accuracy: 0.7454 - val_loss: 0.6514 - val_accuracy: 0.7804\n",
            "Epoch 11/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.7198 - accuracy: 0.7514 - val_loss: 0.6442 - val_accuracy: 0.7792\n",
            "Epoch 12/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.7021 - accuracy: 0.7590 - val_loss: 0.6237 - val_accuracy: 0.7924\n",
            "Epoch 13/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.6799 - accuracy: 0.7657 - val_loss: 0.6989 - val_accuracy: 0.7697\n",
            "Epoch 14/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.6674 - accuracy: 0.7705 - val_loss: 0.6180 - val_accuracy: 0.7921\n",
            "Epoch 15/100\n",
            "781/781 [==============================] - 338s 432ms/step - loss: 0.6528 - accuracy: 0.7729 - val_loss: 0.6318 - val_accuracy: 0.7874\n",
            "Epoch 16/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.6346 - accuracy: 0.7823 - val_loss: 0.6006 - val_accuracy: 0.8052\n",
            "Epoch 17/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.6297 - accuracy: 0.7842 - val_loss: 0.5525 - val_accuracy: 0.8169\n",
            "Epoch 18/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.6189 - accuracy: 0.7884 - val_loss: 0.6283 - val_accuracy: 0.7906\n",
            "Epoch 19/100\n",
            "781/781 [==============================] - 338s 432ms/step - loss: 0.6149 - accuracy: 0.7898 - val_loss: 0.5747 - val_accuracy: 0.8062\n",
            "Epoch 20/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.5949 - accuracy: 0.7957 - val_loss: 0.5999 - val_accuracy: 0.8032\n",
            "Epoch 21/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5941 - accuracy: 0.7959 - val_loss: 0.6285 - val_accuracy: 0.7998\n",
            "Epoch 22/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.5853 - accuracy: 0.7990 - val_loss: 0.5101 - val_accuracy: 0.8291\n",
            "Epoch 23/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5760 - accuracy: 0.8034 - val_loss: 0.5750 - val_accuracy: 0.8072\n",
            "Epoch 24/100\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.5673 - accuracy: 0.8052 - val_loss: 0.5095 - val_accuracy: 0.8326\n",
            "Epoch 25/100\n",
            "781/781 [==============================] - 338s 432ms/step - loss: 0.5682 - accuracy: 0.8068 - val_loss: 0.5929 - val_accuracy: 0.8147\n",
            "Epoch 26/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5665 - accuracy: 0.8063 - val_loss: 0.5861 - val_accuracy: 0.8092\n",
            "Epoch 27/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.5565 - accuracy: 0.8101 - val_loss: 0.5954 - val_accuracy: 0.8089\n",
            "Epoch 28/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5497 - accuracy: 0.8117 - val_loss: 0.5215 - val_accuracy: 0.8261\n",
            "Epoch 29/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.5437 - accuracy: 0.8124 - val_loss: 0.5559 - val_accuracy: 0.8219\n",
            "Epoch 30/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5418 - accuracy: 0.8125 - val_loss: 0.5440 - val_accuracy: 0.8197\n",
            "Epoch 31/100\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.5394 - accuracy: 0.8147 - val_loss: 0.5730 - val_accuracy: 0.8100\n",
            "Epoch 32/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.5364 - accuracy: 0.8144 - val_loss: 0.5402 - val_accuracy: 0.8282\n",
            "Epoch 33/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.5284 - accuracy: 0.8179 - val_loss: 0.5247 - val_accuracy: 0.8260\n",
            "Epoch 34/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5306 - accuracy: 0.8178 - val_loss: 0.5379 - val_accuracy: 0.8264\n",
            "Epoch 35/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.5267 - accuracy: 0.8193 - val_loss: 0.4851 - val_accuracy: 0.8400\n",
            "Epoch 36/100\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.5192 - accuracy: 0.8235 - val_loss: 0.5575 - val_accuracy: 0.8173\n",
            "Epoch 37/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.5174 - accuracy: 0.8231 - val_loss: 0.6083 - val_accuracy: 0.8134\n",
            "Epoch 38/100\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.5156 - accuracy: 0.8231 - val_loss: 0.5404 - val_accuracy: 0.8253\n",
            "Epoch 39/100\n",
            "781/781 [==============================] - 341s 436ms/step - loss: 0.5050 - accuracy: 0.8272 - val_loss: 0.5055 - val_accuracy: 0.8367\n",
            "Epoch 40/100\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.5080 - accuracy: 0.8269 - val_loss: 0.5229 - val_accuracy: 0.8323\n",
            "Epoch 41/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.5053 - accuracy: 0.8264 - val_loss: 0.5781 - val_accuracy: 0.8168\n",
            "Epoch 42/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.5074 - accuracy: 0.8258 - val_loss: 0.5614 - val_accuracy: 0.8235\n",
            "Epoch 43/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.4972 - accuracy: 0.8314 - val_loss: 0.5688 - val_accuracy: 0.8271\n",
            "Epoch 44/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.5028 - accuracy: 0.8291 - val_loss: 0.4946 - val_accuracy: 0.8409\n",
            "Epoch 45/100\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.4977 - accuracy: 0.8282 - val_loss: 0.5215 - val_accuracy: 0.8319\n",
            "Epoch 46/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4902 - accuracy: 0.8301 - val_loss: 0.5435 - val_accuracy: 0.8288\n",
            "Epoch 47/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4923 - accuracy: 0.8291 - val_loss: 0.5329 - val_accuracy: 0.8315\n",
            "Epoch 48/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4916 - accuracy: 0.8303 - val_loss: 0.5733 - val_accuracy: 0.8189\n",
            "Epoch 49/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4911 - accuracy: 0.8302 - val_loss: 0.4957 - val_accuracy: 0.8384\n",
            "Epoch 50/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.4871 - accuracy: 0.8329 - val_loss: 0.5134 - val_accuracy: 0.8347\n",
            "Epoch 51/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4822 - accuracy: 0.8383 - val_loss: 0.5942 - val_accuracy: 0.8146\n",
            "Epoch 52/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4945 - accuracy: 0.8304 - val_loss: 0.5627 - val_accuracy: 0.8256\n",
            "Epoch 53/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4816 - accuracy: 0.8352 - val_loss: 0.5796 - val_accuracy: 0.8196\n",
            "Epoch 54/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4833 - accuracy: 0.8351 - val_loss: 0.5618 - val_accuracy: 0.8236\n",
            "Epoch 55/100\n",
            "781/781 [==============================] - 340s 436ms/step - loss: 0.4798 - accuracy: 0.8378 - val_loss: 0.5294 - val_accuracy: 0.8328\n",
            "Epoch 56/100\n",
            "781/781 [==============================] - 338s 433ms/step - loss: 0.4839 - accuracy: 0.8334 - val_loss: 0.5207 - val_accuracy: 0.8355\n",
            "Epoch 57/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.4760 - accuracy: 0.8361 - val_loss: 0.5603 - val_accuracy: 0.8289\n",
            "Epoch 58/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.4768 - accuracy: 0.8374 - val_loss: 0.4860 - val_accuracy: 0.8442\n",
            "Epoch 59/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4708 - accuracy: 0.8387 - val_loss: 0.5324 - val_accuracy: 0.8302\n",
            "Epoch 60/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.4753 - accuracy: 0.8375 - val_loss: 0.5033 - val_accuracy: 0.8374\n",
            "Epoch 61/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.4681 - accuracy: 0.8397 - val_loss: 0.5743 - val_accuracy: 0.8234\n",
            "Epoch 62/100\n",
            "781/781 [==============================] - 339s 434ms/step - loss: 0.4826 - accuracy: 0.8356 - val_loss: 0.4757 - val_accuracy: 0.8466\n",
            "Epoch 63/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4733 - accuracy: 0.8386 - val_loss: 0.4871 - val_accuracy: 0.8471\n",
            "Epoch 64/100\n",
            "781/781 [==============================] - 339s 435ms/step - loss: 0.4711 - accuracy: 0.8398 - val_loss: 0.5047 - val_accuracy: 0.8382\n",
            "Epoch 65/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.4692 - accuracy: 0.8417 - val_loss: 0.5243 - val_accuracy: 0.8354\n",
            "Epoch 66/100\n",
            "781/781 [==============================] - 341s 437ms/step - loss: 0.4662 - accuracy: 0.8407 - val_loss: 0.5518 - val_accuracy: 0.8299\n",
            "Epoch 67/100\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.4703 - accuracy: 0.8373 - val_loss: 0.5353 - val_accuracy: 0.8364\n",
            "Epoch 68/100\n",
            "781/781 [==============================] - 340s 436ms/step - loss: 0.4644 - accuracy: 0.8410 - val_loss: 0.4981 - val_accuracy: 0.8443\n",
            "Epoch 69/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.4579 - accuracy: 0.8433 - val_loss: 0.4934 - val_accuracy: 0.8413\n",
            "Epoch 70/100\n",
            "781/781 [==============================] - 340s 435ms/step - loss: 0.4677 - accuracy: 0.8376 - val_loss: 0.5209 - val_accuracy: 0.8408\n",
            "Epoch 71/100\n",
            "781/781 [==============================] - 341s 437ms/step - loss: 0.4628 - accuracy: 0.8426 - val_loss: 0.5374 - val_accuracy: 0.8356\n",
            "Epoch 72/100\n",
            "781/781 [==============================] - 336s 431ms/step - loss: 0.4595 - accuracy: 0.8428 - val_loss: 0.5088 - val_accuracy: 0.8435\n",
            "Epoch 73/100\n",
            "781/781 [==============================] - 339s 435ms/step - loss: 0.4639 - accuracy: 0.8416 - val_loss: 0.5423 - val_accuracy: 0.8281\n",
            "Epoch 74/100\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.4557 - accuracy: 0.8435 - val_loss: 0.5264 - val_accuracy: 0.8421\n",
            "Epoch 75/100\n",
            "396/781 [==============>...............] - ETA: 2:40 - loss: 0.4469 - accuracy: 0.8483Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7wMjiqy4QkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "896c7aee-3cbe-4c99-b101-c54d6707fbb8"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png')\n",
        "\tpyplot.close()\n",
        "# learning curves\n",
        "summarize_diagnostics(history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ff74771895c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    }
  ]
}